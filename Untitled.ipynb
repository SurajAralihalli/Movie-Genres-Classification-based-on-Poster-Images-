{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras.utils\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import fashion_mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import keras.losses\n",
    "\n",
    "(train_X,train_Y), (test_X,test_Y) = fashion_mnist.load_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (60000, 28, 28) (60000,)\n",
      "Testing data shape :  (10000, 28, 28) (10000,)\n",
      "Total number of outputs :  10\n",
      "Output classes :  [0 1 2 3 4 5 6 7 8 9]\n",
      "Original label: 9\n",
      "After conversion to one-hot: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 8)         80        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 26, 26, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 26, 26, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 16)        1168      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 22, 32)        4640      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3872)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               495744    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 502,922\n",
      "Trainable params: 502,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Print out the details\n",
    "print('Training data shape : ', train_X.shape, train_Y.shape)\n",
    "print('Testing data shape : ', test_X.shape, test_Y.shape)\n",
    "\n",
    "classes = np.unique(train_Y)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)\n",
    "\n",
    "#Sample data\n",
    "plt.subplot(121)\n",
    "plt.imshow(train_X[12423], cmap='gray')\n",
    "plt.title(\"Class : {}\".format(train_Y[12423]))\n",
    "\n",
    "\n",
    "#prepare data to feed into the CNN\n",
    "# -1 in the first parameter means we ask numpy to figure out\n",
    "# what that should be. It finds out that it is 48000\n",
    "# because we split 60000 instances into 48000 training and 12000 testing\n",
    "train_X = train_X.reshape(-1, 28,28, 1)\n",
    "test_X = test_X.reshape(-1, 28,28, 1)\n",
    "\n",
    "#COnvert into float and normalize\n",
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "train_X = train_X / 255\n",
    "test_X = test_X / 255\n",
    "\n",
    "#Convert the labels into one-hot\n",
    "train_Y_one_hot = keras.utils.to_categorical(train_Y)\n",
    "test_Y_one_hot = keras.utils.to_categorical(test_Y)\n",
    "\n",
    "# Display the change for category label using one-hot encoding\n",
    "print('Original label:', train_Y[0])\n",
    "print('After conversion to one-hot:', train_Y_one_hot[0])\n",
    "\n",
    "#Split data into training and validation\n",
    "train_X,valid_X,train_label,valid_label = train_test_split(train_X, \n",
    "                                                           train_Y_one_hot, \n",
    "                                                           test_size=0.2)\n",
    "#We are ready\n",
    "batch_size = 64\n",
    "epochs=6\n",
    "num_classes = 10\n",
    "\n",
    "fashion_model = Sequential()\n",
    "fashion_model.add(Conv2D(8, kernel_size=3,input_shape=(28,28,1),padding='valid'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))\n",
    "fashion_model.add(Dropout(0.2))\n",
    "\n",
    "fashion_model.add(Conv2D(16,kernel_size=3, padding='valid'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))\n",
    "fashion_model.add(Dropout(0.2))\n",
    "\n",
    "fashion_model.add(Conv2D(32, kernel_size=3,padding='valid'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))\n",
    "fashion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "fashion_model.add(Flatten())\n",
    "\n",
    "fashion_model.add(Dense(128))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))       \n",
    "fashion_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "fashion_model.summary() \n",
    "\n",
    "\n",
    "#Compile as usual\n",
    "\n",
    "fashion_model.compile(loss=\"categorical_crossentropy\", \n",
    "                      optimizer=\"Adam\" ,metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_X[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/1\n",
      "47296/48000 [============================>.] - ETA: 0s - loss: 0.5247 - acc: 0.8061"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a4925c11b5e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Lets train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m fashion_train = fashion_model.fit(train_X, train_label, batch_size=batch_size,\n\u001b[0;32m----> 3\u001b[0;31m                                   epochs=1,verbose=1)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Test out the Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Lets train\n",
    "fashion_train = fashion_model.fit(train_X, train_label, batch_size=batch_size,\n",
    "                                  epochs=1,verbose=1)\n",
    "\n",
    "#Test out the Model\n",
    "\n",
    "test_eval = fashion_model.evaluate(test_X, test_Y_one_hot, verbose=0)\n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
